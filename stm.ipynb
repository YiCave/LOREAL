{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42fb421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping two datasets by videoid first\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the latest processed comments (from your spam detection pipeline)\n",
    "comments_df = pd.read_csv('../complete_comments_with_features.csv')\n",
    "print(f\"Loaded comments: {len(comments_df):,} rows\")\n",
    "\n",
    "# Load original videos dataset\n",
    "videos_df = pd.read_csv('../dataset/videos.csv')\n",
    "print(f\"Loaded videos: {len(videos_df):,} rows\")\n",
    "\n",
    "# Check unique videoIds in each dataset\n",
    "unique_videos_in_comments = comments_df['videoId'].nunique()\n",
    "unique_videos_in_videos = videos_df['videoId'].nunique()\n",
    "\n",
    "print(f\"\\nUnique videoIds in comments: {unique_videos_in_comments:,}\")\n",
    "print(f\"Unique videoIds in videos: {unique_videos_in_videos:,}\")\n",
    "\n",
    "# Find videos without comments and comments without videos\n",
    "videos_with_comments = set(comments_df['videoId'].unique())\n",
    "videos_in_dataset = set(videos_df['videoId'].unique())\n",
    "\n",
    "videos_without_comments = videos_in_dataset - videos_with_comments\n",
    "comments_without_videos = videos_with_comments - videos_in_dataset\n",
    "\n",
    "print(f\"\\nMERGE STATISTICS:\")\n",
    "print(f\"Videos without any comments: {len(videos_without_comments):,}\")\n",
    "print(f\"Comments referencing non-existent videos: {len(comments_without_videos):,}\")\n",
    "\n",
    "# Show some examples if they exist\n",
    "if videos_without_comments:\n",
    "    print(f\"\\nExample videos without comments: {list(videos_without_comments)[:5]}\")\n",
    "if comments_without_videos:\n",
    "    print(f\"Example videoIds in comments but not in videos: {list(comments_without_videos)[:5]}\")\n",
    "\n",
    "# Perform the merge - keeping all comments that have matching videos\n",
    "merged_df = comments_df.merge(videos_df, on='videoId', how='inner', suffixes=('_comment', '_video'))\n",
    "\n",
    "print(f\"\\nMERGE RESULTS:\")\n",
    "print(f\"Comments before merge: {len(comments_df):,}\")\n",
    "print(f\"Comments after merge: {len(merged_df):,}\")\n",
    "print(f\"Comments lost in merge: {len(comments_df) - len(merged_df):,}\")\n",
    "print(f\"Videos included in merge: {merged_df['videoId'].nunique():,}\")\n",
    "\n",
    "# Show what happens to comment IDs - they are preserved!\n",
    "print(f\"\\nComment IDs preserved: All {len(merged_df):,} comment IDs remain intact\")\n",
    "print(f\"Each row still represents one comment, now enriched with video metadata\")\n",
    "\n",
    "print(f\"\\nMERGED DATASET COLUMNS:\")\n",
    "print(\"Comment columns:\", [col for col in merged_df.columns if col.endswith('_comment') or col in ['commentId', 'textOriginal', 'likeCount_comment']])\n",
    "print(\"Video columns:\", [col for col in merged_df.columns if col.endswith('_video') or col in ['title', 'description', 'tags']])\n",
    "print(\"Shared columns:\", [col for col in merged_df.columns if not col.endswith('_comment') and not col.endswith('_video') and col != 'videoId'])\n",
    "\n",
    "# Display merged dataframe in table format\n",
    "print(\"\\nSAMPLE OF MERGED DATA:\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Select key columns for easier viewing\n",
    "key_columns = ['commentId', 'videoId', 'textOriginal', 'title', 'description', 'likeCount_comment', 'viewCount']\n",
    "display_df = merged_df[key_columns].head()\n",
    "\n",
    "# Set pandas display options for better table formatting\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(display_df.to_string(index=False))\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39971220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
